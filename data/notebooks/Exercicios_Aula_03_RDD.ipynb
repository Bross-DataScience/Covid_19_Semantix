{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicios RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = sc.textFile('file:///opt/spark/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080',\n",
       " '========================================',\n",
       " '20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\",\n",
       " '20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077',\n",
       " '20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1',\n",
       " '20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms',\n",
       " '20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown',\n",
       " '20/03/18 20:31:10 INFO server.Server: Started @1504ms',\n",
       " '20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\",\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(log.count())\n",
    "log.first()\n",
    "log.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = log.flatMap(lambda line: line.split(' '))\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark',\n",
       " 'Command:',\n",
       " '/opt/java/bin/java',\n",
       " '-cp',\n",
       " '/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       " '-Xmx1g',\n",
       " 'org.apache.spark.deploy.master.Master',\n",
       " '--host',\n",
       " 'localhost',\n",
       " '--port']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark',\n",
       " 'command:',\n",
       " '/opt/java/bin/java',\n",
       " '-cp',\n",
       " '/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       " '-xmx1g',\n",
       " 'org.apache.spark.deploy.master.master',\n",
       " '--host',\n",
       " 'localhost',\n",
       " '--port']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase = words.map(lambda word: word.lower())\n",
    "lowercase.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['spark',\n",
       " 'command:',\n",
       " '/opt/java/bin/java',\n",
       " '-cp',\n",
       " '/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       " '-xmx1g',\n",
       " 'org.apache.spark.deploy.master.master',\n",
       " '--host',\n",
       " 'localhost',\n",
       " '--port']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase_major2 = lowercase.filter(lambda word: len(word) > 2)\n",
    "print(lowercase_major2.count())\n",
    "lowercase_major2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark', 1),\n",
       " ('command:', 1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('-cp', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_1 = lowercase_major2.map(lambda word: (word,1))\n",
    "words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_reduce = words_1.reduceByKey(lambda key1, key2 : key1 + key2)\n",
    "words_reduce.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'masterui'\", 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('--host', 1),\n",
       " ('--port', 1),\n",
       " ('--webui-port', 1),\n",
       " ('-cp', 1),\n",
       " ('-xmx1g', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('0.0.0.0,', 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_order = words_reduce.sortBy(lambda word: word[0])\n",
    "words_order.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_order_qtd = words_reduce.sortBy(lambda word: -word[1])\n",
    "words_order_qtd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_order_filter = words_order_qtd.filter(lambda word: word[1] > 1)\n",
    "words_order_filter.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_order_filter.saveAsTextFile('/user/bross/logs_count_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-04-05 15:03 /user/bross/data\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-04-07 15:08 /user/bross/logs_count_word\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/bross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicios RDD Usando Partições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_partitions = sc.textFile('file:///opt/spark/logs', 10)\n",
    "log_partitions.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_partitions = log_partitions.flatMap(lambda line: line.split(' '), 5)\n",
    "words_partitions.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_lowercase_partitions = words_partitions.map(lambda word: word.lower(), 8)\n",
    "words_lowercase_partitions.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_partitions = words_lowercase_partitions.map(lambda word: (word,1), 8)\n",
    "words_count_partitions.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_reduce_partitions = words_count_partitions.reduceByKey(lambda key1, key2: key1 + key2, 5)\n",
    "words_reduce_partitions.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_reduce_partitions.saveAsTextFile('/user/bross/logs_count_word_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-04-07 18:16 /user/bross/logs_count_word_5/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        575 2022-04-07 18:16 /user/bross/logs_count_word_5/part-00000\r\n",
      "-rw-r--r--   2 root supergroup        208 2022-04-07 18:16 /user/bross/logs_count_word_5/part-00001\r\n",
      "-rw-r--r--   2 root supergroup        444 2022-04-07 18:16 /user/bross/logs_count_word_5/part-00002\r\n",
      "-rw-r--r--   2 root supergroup        772 2022-04-07 18:16 /user/bross/logs_count_word_5/part-00003\r\n",
      "-rw-r--r--   2 root supergroup        785 2022-04-07 18:16 /user/bross/logs_count_word_5/part-00004\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/bross/logs_count_word_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
